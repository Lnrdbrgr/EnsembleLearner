{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hotel Cancellation Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 00: Setup and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EnsembleLearner import EnsembleLearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 01: Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_orig = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hotel                              object\n",
       "is_canceled                         int64\n",
       "lead_time                           int64\n",
       "arrival_date_year                   int64\n",
       "arrival_date_month                 object\n",
       "arrival_date_week_number            int64\n",
       "arrival_date_day_of_month           int64\n",
       "stays_in_weekend_nights             int64\n",
       "stays_in_week_nights                int64\n",
       "adults                              int64\n",
       "children                          float64\n",
       "babies                              int64\n",
       "meal                               object\n",
       "country                            object\n",
       "market_segment                     object\n",
       "distribution_channel               object\n",
       "is_repeated_guest                   int64\n",
       "previous_cancellations              int64\n",
       "previous_bookings_not_canceled      int64\n",
       "reserved_room_type                 object\n",
       "assigned_room_type                 object\n",
       "booking_changes                     int64\n",
       "deposit_type                       object\n",
       "agent                             float64\n",
       "company                           float64\n",
       "days_in_waiting_list                int64\n",
       "customer_type                      object\n",
       "adr                               float64\n",
       "required_car_parking_spaces         int64\n",
       "total_of_special_requests           int64\n",
       "reservation_status_date            object\n",
       "name                               object\n",
       "email                              object\n",
       "phone-number                       object\n",
       "credit_card                        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check some descriptives\n",
    "data_orig.dtypes\n",
    "#data_orig.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2015, 2016, 2017], dtype=int64)"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf['arrival_date_year'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that do not have explanatory value\n",
    "data_clean = data_orig.drop(['reservation_status_date', 'name', 'email', 'phone-number', 'credit_card'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_canceled                         int64\n",
       "lead_time                           int64\n",
       "arrival_date_year                   int64\n",
       "arrival_date_week_number            int64\n",
       "arrival_date_day_of_month           int64\n",
       "stays_in_weekend_nights             int64\n",
       "stays_in_week_nights                int64\n",
       "adults                              int64\n",
       "children                          float64\n",
       "babies                              int64\n",
       "is_repeated_guest                   int64\n",
       "previous_cancellations              int64\n",
       "previous_bookings_not_canceled      int64\n",
       "booking_changes                     int64\n",
       "agent                             float64\n",
       "company                           float64\n",
       "days_in_waiting_list                int64\n",
       "adr                               float64\n",
       "required_car_parking_spaces         int64\n",
       "total_of_special_requests           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check numeric columns if it makes sense to leave them as numeric or should be converted to factors\n",
    "data_clean.dtypes[data_clean.dtypes != 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create categorical dummies for a column\n",
    "def create_dummies(data, column):\n",
    "    data_clean = pd.concat([\n",
    "        data.drop(column, axis=1),\n",
    "        pd.get_dummies(data[column])\n",
    "    ], axis=1)\n",
    "    return data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduce dummies for numerical values where categorical makes more sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 02.1 Preprocessing Time Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrival year\n",
    "data_clean = create_dummies(data_clean, 'arrival_date_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrival week number, drop month\n",
    "data_clean = create_dummies(data_clean, 'arrival_date_week_number')\n",
    "data_clean.drop('arrival_date_month', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrival date day of month - bin to four groups\n",
    "data_clean['arrival_date_period_of_month'] = pd.cut(data_clean['arrival_date_day_of_month'], bins=4)\n",
    "data_clean = create_dummies(data_clean, 'arrival_date_period_of_month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 02.2 Preprocessing Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>cancelled_mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.178878</td>\n",
       "      <td>2566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>2480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.172048</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>241.0</td>\n",
       "      <td>0.132885</td>\n",
       "      <td>1189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.074232</td>\n",
       "      <td>1172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.077135</td>\n",
       "      <td>726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>314.0</td>\n",
       "      <td>0.184783</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.806316</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>85.0</td>\n",
       "      <td>0.204082</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>243.0</td>\n",
       "      <td>0.065527</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.087879</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.235955</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     agent  cancelled_mean  count\n",
       "13    14.0        0.178878   2566\n",
       "6      7.0        0.137500   2480\n",
       "176  250.0        0.172048   1982\n",
       "168  241.0        0.132885   1189\n",
       "26    28.0        0.074232   1172\n",
       "38    40.0        0.077135    726\n",
       "218  314.0        0.184783    644\n",
       "27    29.0        0.806316    475\n",
       "73    85.0        0.204082    392\n",
       "170  243.0        0.065527    351\n",
       "25    27.0        0.087879    330\n",
       "10    11.0        0.235955    267"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check agent\n",
    "agent_analysis = data_clean.groupby('agent').agg(\n",
    "    cancelled_mean = ('is_canceled', 'mean'),\n",
    "    count = ('is_canceled', 'count')\n",
    ")\\\n",
    "    .reset_index() \\\n",
    "    .sort_values('count', ascending=False) \\\n",
    "    .query('(cancelled_mean >= 0.75 | cancelled_mean < 0.25) & count > 250')\n",
    "\n",
    "agent_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep those agents which seem to have explanatory power and enough bookings and make dummies\n",
    "data_clean['agent_keep'] = np.where((data_clean['agent'].isin(list(agent_analysis['agent']))), data_clean['agent'], np.nan)\n",
    "data_clean = create_dummies(data_clean, 'agent_keep')\n",
    "data_clean.drop('agent', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 02.3 Preprocessing Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>cancelled_mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.083591</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>223.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>153.0</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>174.0</td>\n",
       "      <td>0.168224</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  cancelled_mean  count\n",
       "17      40.0        0.083591    646\n",
       "122    223.0        0.142857    560\n",
       "20      45.0        0.125000    168\n",
       "84     153.0        0.220000    150\n",
       "93     174.0        0.168224    107"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check agent\n",
    "company_analysis = data_clean.groupby('company').agg(\n",
    "    cancelled_mean = ('is_canceled', 'mean'),\n",
    "    count = ('is_canceled', 'count')\n",
    ")\\\n",
    "    .reset_index() \\\n",
    "    .sort_values('count', ascending=False) \\\n",
    "    .query('(cancelled_mean >= 0.75 | cancelled_mean < 0.25) & count > 100')\n",
    "\n",
    "company_analysis.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep those companies which seem to have explanatory power and enough bookings and make dummies\n",
    "data_clean['company_keep'] = np.where((data_clean['company'].isin(list(company_analysis['company']))), data_clean['company'], np.nan)\n",
    "data_clean = create_dummies(data_clean, 'company_keep')\n",
    "data_clean.drop('company', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 02.4 Preprocessing Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>cancelled_mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>GBR</td>\n",
       "      <td>0.199788</td>\n",
       "      <td>8489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>FRA</td>\n",
       "      <td>0.187578</td>\n",
       "      <td>7245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>DEU</td>\n",
       "      <td>0.167825</td>\n",
       "      <td>5178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>IRL</td>\n",
       "      <td>0.245937</td>\n",
       "      <td>2338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BEL</td>\n",
       "      <td>0.197612</td>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  cancelled_mean  count\n",
       "55     GBR        0.199788   8489\n",
       "52     FRA        0.187578   7245\n",
       "39     DEU        0.167825   5178\n",
       "71     IRL        0.245937   2338\n",
       "12     BEL        0.197612   1675"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check country\n",
    "country_analysis = data_clean.groupby('country').agg(\n",
    "    cancelled_mean = ('is_canceled', 'mean'),\n",
    "    count = ('is_canceled', 'count')\n",
    ")\\\n",
    "    .reset_index() \\\n",
    "    .sort_values('count', ascending=False) \\\n",
    "    .query('(cancelled_mean >= 0.75 | cancelled_mean < 0.25) & count > 500')\n",
    "\n",
    "country_analysis.head(5)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep those countries which seem to have explanatory power and enough bookings and make dummies\n",
    "data_clean['country_keep'] = np.where((data_clean['country'].isin(list(country_analysis['country']))), data_clean['country'], np.nan)\n",
    "data_clean = create_dummies(data_clean, 'country_keep')\n",
    "data_clean.drop('country', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 02.5 Preprocessing market_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_segment</th>\n",
       "      <th>cancelled_mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Direct</td>\n",
       "      <td>0.152395</td>\n",
       "      <td>8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Corporate</td>\n",
       "      <td>0.186261</td>\n",
       "      <td>3683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Complementary</td>\n",
       "      <td>0.132438</td>\n",
       "      <td>521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  market_segment  cancelled_mean  count\n",
       "3         Direct        0.152395   8852\n",
       "2      Corporate        0.186261   3683\n",
       "1  Complementary        0.132438    521"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check country\n",
    "market_segment_analysis = data_clean.groupby('market_segment').agg(\n",
    "    cancelled_mean = ('is_canceled', 'mean'),\n",
    "    count = ('is_canceled', 'count')\n",
    ")\\\n",
    "    .reset_index() \\\n",
    "    .sort_values('count', ascending=False) \\\n",
    "    .query('(cancelled_mean >= 0.75 | cancelled_mean < 0.25) & count > 500')\n",
    "\n",
    "market_segment_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dummies\n",
    "data_clean = create_dummies(data_clean, 'market_segment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above with market_segment, distribution_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hotel                          2\n",
       "is_canceled                    2\n",
       "lead_time                    473\n",
       "arrival_date_day_of_month     31\n",
       "stays_in_weekend_nights       17\n",
       "                            ... \n",
       "Direct                         2\n",
       "Groups                         2\n",
       "Offline TA/TO                  2\n",
       "Online TA                      2\n",
       "Undefined                      2\n",
       "Length: 120, dtype: int64"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_clean.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37161573615569105\n",
      "0.48323646468096937\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(data_clean['is_canceled']))\n",
    "print(np.std(data_clean['is_canceled']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6132339684961757\n",
      "0.12999750381520636\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(data_clean['is_canceled']) + 0.5*np.std(data_clean['is_canceled']))\n",
    "print(np.mean(data_clean['is_canceled']) - 0.5*np.std(data_clean['is_canceled']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hotel                   object\n",
       "meal                    object\n",
       "country                 object\n",
       "market_segment          object\n",
       "distribution_channel    object\n",
       "reserved_room_type      object\n",
       "assigned_room_type      object\n",
       "deposit_type            object\n",
       "customer_type           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.dtypes[data_clean.dtypes == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that do not have explanatory value - include country later again\n",
    "data_clean = data_orig.drop(['reservation_status_date', 'name', 'email', 'phone-number', 'credit_card', 'country'], axis = 1)\n",
    "\n",
    "# make dummies from categorical values\n",
    "data_clean = pd.get_dummies(data_clean)\n",
    "\n",
    "# binarise time variables\n",
    "#data_clean = pd.concat(\n",
    "#    [\n",
    "#        data_clean.drop(['arrival_date_year', 'arrival_date_week_number', 'arrival_date_day_of_month'], axis = 1),\n",
    "#        pd.get_dummies(data_clean['arrival_date_year']),\n",
    "#        pd.get_dummies(data_clean['arrival_date_week_number']),\n",
    "#        pd.get_dummies(data_clean['arrival_date_day_of_month'])\n",
    "#    ],\n",
    "#    axis = 1\n",
    "#)\n",
    "\n",
    "# binarise agent and company variable\n",
    "#data_clean = pd.concat(\n",
    "#    [\n",
    "#        data_clean.drop(['agent', 'company'], axis = 1),\n",
    "#        pd.get_dummies(data_clean['agent']),\n",
    "#        pd.get_dummies(data_clean['company'])\n",
    "#    ],\n",
    "#    axis = 1\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>null_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>children</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>agent</td>\n",
       "      <td>11403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>company</td>\n",
       "      <td>79106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  null_sum\n",
       "8   children         2\n",
       "14     agent     11403\n",
       "15   company     79106"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for nans\n",
    "pd.DataFrame(data_clean.isnull().sum()).reset_index() \\\n",
    "    .rename(columns = {0: 'null_sum'}) \\\n",
    "    .query('null_sum > 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only two where there are nans for children, assuming no children traveled\n",
    "data_clean['children'] = data_clean['children'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.drop(['agent', 'company'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in train and evaluation set\n",
    "dep_variable = 'is_canceled'\n",
    "X = data_clean.drop(dep_variable, axis = 1)\n",
    "X = (X-X.mean())/X.std()\n",
    "y = data_clean[dep_variable]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "X_train = X_train.iloc[0:1000]\n",
    "y_train = y_train.iloc[0:1000]\n",
    "X_val = X_val[0:100]\n",
    "y_val = y_val[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03: Training and Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "def matrix_acc(pred_matrix, truth_series):\n",
    "    acc_dict = dict()\n",
    "    for col in pred_matrix.columns:\n",
    "        acc_dict[col] = round(accuracy_score(pred_matrix[col], truth_series), 4)\n",
    "    return pd.DataFrame([acc_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EL_pred     knn  GaussianNB  DecisionTree     SVM  RandomForest  \\\n",
      "0   0.8333  0.7833        0.46          0.78  0.7667        0.7967   \n",
      "\n",
      "   LogisticRegression  \n",
      "0              0.7833  \n",
      "   EL_pred   knn  GaussianNB  DecisionTree  SVM  RandomForest  \\\n",
      "0     0.85  0.81        0.46          0.74  0.8          0.85   \n",
      "\n",
      "   LogisticRegression  \n",
      "0                0.83  \n"
     ]
    }
   ],
   "source": [
    "import EnsembleLearner\n",
    "import importlib\n",
    "importlib.reload(EnsembleLearner)\n",
    "from EnsembleLearner import EnsembleLearner\n",
    "\n",
    "models = ['knn', 'GaussianNB', 'DecisionTree', 'SVM','RandomForest', 'LogisticRegression'] # 'MLP', 'XGBoost'\n",
    "EL = EnsembleLearner(X = X_train, y = y_train, models = models, ensemble_learner = 'DecisionTree')\n",
    "training_pred_df = EL.train_ensemble_learner(return_training_predictions=True, verbose = False)\n",
    "print(matrix_acc(training_pred_df.drop('truth', axis=1), training_pred_df['truth']))\n",
    "pred = EL.predict(X_val, verbose = False)\n",
    "print(matrix_acc(pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04: Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here need to ensure that all dummy variables and columns of test set include the original ones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a063a9d6d4095dba70f7d4a438ef288e94ffec589b0525f5b20de998ec61033a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
