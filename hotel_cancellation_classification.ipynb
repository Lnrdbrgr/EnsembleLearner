{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hotel Cancellation Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 00: Setup and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EnsembleLearner import EnsembleLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_weeks = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 01: Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_orig = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add artificial is_canceled column so the test set can follow the transformations done on the train set\n",
    "test_data['is_canceled'] = np.nan\n",
    "\n",
    "# bind the datasets\n",
    "data = pd.concat([data_orig, test_data], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check some descriptives\n",
    "#data_orig.dtypes\n",
    "#data_orig.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 02: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that do not have explanatory value\n",
    "data_clean = data_orig.drop(['reservation_status_date', 'name', 'email', 'phone-number', 'credit_card'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create categorical dummies for a column\n",
    "def create_dummies(data, column):\n",
    "    data_clean = pd.concat([\n",
    "        data.drop(column, axis=1),\n",
    "        pd.get_dummies(data[column])\n",
    "    ], axis=1)\n",
    "    return data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 02.1 Preprocessing Time Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrival year\n",
    "data_clean = create_dummies(data_clean, 'arrival_date_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrival week number, drop month\n",
    "if include_weeks:\n",
    "    data_clean = create_dummies(data_clean, 'arrival_date_week_number')\n",
    "else:\n",
    "    data_clean.drop('arrival_date_week_number', axis=1, inplace=True)\n",
    "\n",
    "data_clean.drop('arrival_date_month', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>cancelled_mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.455906</td>\n",
       "      <td>1871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.450650</td>\n",
       "      <td>2077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.437309</td>\n",
       "      <td>1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    arrival_date_week_number  cancelled_mean  count\n",
       "24                        25        0.455906   1871\n",
       "17                        18        0.450650   2077\n",
       "19                        20        0.437309   1962"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_orig.groupby('arrival_date_week_number').agg(\n",
    "    cancelled_mean = ('is_canceled', 'mean'),\n",
    "    count = ('is_canceled', 'count')\n",
    ")\\\n",
    "    .reset_index() \\\n",
    "    .sort_values('cancelled_mean', ascending=False) \\\n",
    "    .head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrival date day of month - bin to four groups\n",
    "data_clean['arrival_date_period_of_month'] = pd.cut(data_clean['arrival_date_day_of_month'], bins=4)\n",
    "data_clean = create_dummies(data_clean, 'arrival_date_period_of_month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 02.2 Preprocessing Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>cancelled_mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.178878</td>\n",
       "      <td>2566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>2480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>250.0</td>\n",
       "      <td>0.172048</td>\n",
       "      <td>1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>241.0</td>\n",
       "      <td>0.132885</td>\n",
       "      <td>1189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.074232</td>\n",
       "      <td>1172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     agent  cancelled_mean  count\n",
       "13    14.0        0.178878   2566\n",
       "6      7.0        0.137500   2480\n",
       "176  250.0        0.172048   1982\n",
       "168  241.0        0.132885   1189\n",
       "26    28.0        0.074232   1172"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check agent\n",
    "agent_analysis = data_clean.groupby('agent').agg(\n",
    "    cancelled_mean = ('is_canceled', 'mean'),\n",
    "    count = ('is_canceled', 'count')\n",
    ")\\\n",
    "    .reset_index() \\\n",
    "    .sort_values('count', ascending=False) \\\n",
    "    .query('(cancelled_mean >= 0.75 | cancelled_mean < 0.25) & count > 250')\n",
    "\n",
    "agent_analysis.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep those agents which seem to have explanatory power and enough bookings and make dummies\n",
    "data_clean['agent_keep'] = np.where((data_clean['agent'].isin(list(agent_analysis['agent']))), data_clean['agent'], np.nan)\n",
    "data_clean = create_dummies(data_clean, 'agent_keep')\n",
    "data_clean.drop('agent', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 02.3 Preprocessing Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>cancelled_mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.083591</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>223.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>45.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>153.0</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>174.0</td>\n",
       "      <td>0.168224</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     company  cancelled_mean  count\n",
       "17      40.0        0.083591    646\n",
       "122    223.0        0.142857    560\n",
       "20      45.0        0.125000    168\n",
       "84     153.0        0.220000    150\n",
       "93     174.0        0.168224    107"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check agent\n",
    "company_analysis = data_clean.groupby('company').agg(\n",
    "    cancelled_mean = ('is_canceled', 'mean'),\n",
    "    count = ('is_canceled', 'count')\n",
    ")\\\n",
    "    .reset_index() \\\n",
    "    .sort_values('count', ascending=False) \\\n",
    "    .query('(cancelled_mean >= 0.75 | cancelled_mean < 0.25) & count > 100')\n",
    "\n",
    "company_analysis.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep those companies which seem to have explanatory power and enough bookings and make dummies\n",
    "data_clean['company_keep'] = np.where((data_clean['company'].isin(list(company_analysis['company']))), data_clean['company'], np.nan)\n",
    "data_clean = create_dummies(data_clean, 'company_keep')\n",
    "data_clean.drop('company', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 02.4 Preprocessing Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>cancelled_mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>GBR</td>\n",
       "      <td>0.199788</td>\n",
       "      <td>8489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>FRA</td>\n",
       "      <td>0.187578</td>\n",
       "      <td>7245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>DEU</td>\n",
       "      <td>0.167825</td>\n",
       "      <td>5178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>IRL</td>\n",
       "      <td>0.245937</td>\n",
       "      <td>2338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BEL</td>\n",
       "      <td>0.197612</td>\n",
       "      <td>1675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country  cancelled_mean  count\n",
       "55     GBR        0.199788   8489\n",
       "52     FRA        0.187578   7245\n",
       "39     DEU        0.167825   5178\n",
       "71     IRL        0.245937   2338\n",
       "12     BEL        0.197612   1675"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check country\n",
    "country_analysis = data_clean.groupby('country').agg(\n",
    "    cancelled_mean = ('is_canceled', 'mean'),\n",
    "    count = ('is_canceled', 'count')\n",
    ")\\\n",
    "    .reset_index() \\\n",
    "    .sort_values('count', ascending=False) \\\n",
    "    .query('(cancelled_mean >= 0.75 | cancelled_mean < 0.25) & count > 500')\n",
    "\n",
    "country_analysis.head(5)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep those countries which seem to have explanatory power and enough bookings and make dummies\n",
    "data_clean['country_keep'] = np.where((data_clean['country'].isin(list(country_analysis['country']))), data_clean['country'], np.nan)\n",
    "data_clean = create_dummies(data_clean, 'country_keep')\n",
    "data_clean.drop('country', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 02.5 Preprocessing market_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>market_segment</th>\n",
       "      <th>cancelled_mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Direct</td>\n",
       "      <td>0.152395</td>\n",
       "      <td>8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Corporate</td>\n",
       "      <td>0.186261</td>\n",
       "      <td>3683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Complementary</td>\n",
       "      <td>0.132438</td>\n",
       "      <td>521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  market_segment  cancelled_mean  count\n",
       "3         Direct        0.152395   8852\n",
       "2      Corporate        0.186261   3683\n",
       "1  Complementary        0.132438    521"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check country\n",
    "market_segment_analysis = data_clean.groupby('market_segment').agg(\n",
    "    cancelled_mean = ('is_canceled', 'mean'),\n",
    "    count = ('is_canceled', 'count')\n",
    ")\\\n",
    "    .reset_index() \\\n",
    "    .sort_values('count', ascending=False) \\\n",
    "    .query('(cancelled_mean >= 0.75 | cancelled_mean < 0.25) & count > 500')\n",
    "\n",
    "market_segment_analysis.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep all - make dummies\n",
    "data_clean = create_dummies(data_clean, 'market_segment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 02.6 Perprocessing other object columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hotel',\n",
       " 'meal',\n",
       " 'distribution_channel',\n",
       " 'reserved_room_type',\n",
       " 'assigned_room_type',\n",
       " 'deposit_type',\n",
       " 'customer_type']"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show columns that are still not numerical\n",
    "obj_columns = list(data_clean.columns[data_clean.dtypes == 'object'])\n",
    "obj_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hotel                    2\n",
       "meal                     5\n",
       "distribution_channel     5\n",
       "reserved_room_type      10\n",
       "assigned_room_type      12\n",
       "deposit_type             3\n",
       "customer_type            4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not too many so keep all\n",
    "data_clean[obj_columns].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dummies for all the object columns\n",
    "for attribute in obj_columns:\n",
    "    data_clean = create_dummies(data_clean, attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that all object columns are converted\n",
    "all(data_clean.dtypes != 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_clean.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 02.7 Preprocessing NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>null_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>children</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  null_sum\n",
       "6  children         2"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for nans\n",
    "pd.DataFrame(data_clean.isnull().sum()).reset_index() \\\n",
    "    .rename(columns = {0: 'null_sum'}) \\\n",
    "    .query('null_sum > 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only two where there are nans for children, assuming no children traveled\n",
    "data_clean['children'] = data_clean['children'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data again\n",
    "test_set = data_clean.loc[data_clean['is_canceled'].isnull()]\n",
    "train_set = data_clean.loc[not data_clean['is_canceled'].isnull()]\n",
    "\n",
    "# split data in train and evaluation set\n",
    "dep_variable = 'is_canceled'\n",
    "X = data_clean.drop(dep_variable, axis = 1)\n",
    "X = (X-X.mean())/X.std() # standardise data\n",
    "y = data_clean[dep_variable]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "\n",
    "#### for development ####\n",
    "#X_train = X_train.iloc[0:1000]\n",
    "#y_train = y_train.iloc[0:1000]\n",
    "#X_val = X_val[0:100]\n",
    "#y_val = y_val[0:100]\n",
    "#import EnsembleLearner\n",
    "#import importlib\n",
    "#importlib.reload(EnsembleLearner)\n",
    "#from EnsembleLearner import EnsembleLearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 03: Training and Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to evaluate the prediction outcome\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def matrix_acc(pred_matrix, truth_series):\n",
    "    acc_dict = dict()\n",
    "    for col in pred_matrix.columns:\n",
    "        acc_dict[col] = round(accuracy_score(pred_matrix[col], truth_series), 4)\n",
    "    return pd.DataFrame([acc_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model knn done training Ensemble Learner Training\n",
      "Model GaussianNB done training Ensemble Learner Training\n",
      "Model DecisionTree done training Ensemble Learner Training\n",
      "Model SVM done training Ensemble Learner Training\n",
      "Model RandomForest done training Ensemble Learner Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leona\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model LogisticRegression done training Ensemble Learner Training\n"
     ]
    }
   ],
   "source": [
    "# choose the models\n",
    "models = ['knn', 'GaussianNB', 'DecisionTree', 'SVM','RandomForest', 'LogisticRegression', 'MLP', 'XGBoost'] # , 'MLP', 'XGBoost'\n",
    "\n",
    "# establish the ensemble learner class\n",
    "EL = EnsembleLearner(X = X_train, y = y_train, models = models, ensemble_learner = 'DecisionTree')\n",
    "\n",
    "# train the models and the ensemble learner\n",
    "training_pred_df = EL.train_ensemble_learner(return_training_predictions=True, verbose=True)\n",
    "matrix_acc(training_pred_df.drop('truth', axis=1), training_pred_df['truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the performance on the test set\n",
    "pred = EL.predict(X_val)\n",
    "matrix_acc(pred, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 04: Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model again on whole data\n",
    "\n",
    "# choose the models\n",
    "models = ['knn', 'GaussianNB', 'DecisionTree', 'SVM','RandomForest', 'LogisticRegression', 'MLP', 'XGBoost'] # , 'MLP', 'XGBoost'\n",
    "\n",
    "# establish the ensemble learner class\n",
    "EL = EnsembleLearner(X = X, y = y, models = models, ensemble_learner = 'DecisionTree')\n",
    "\n",
    "# train the models and the ensemble learner\n",
    "training_pred_df = EL.train_ensemble_learner(return_training_predictions=True, verbose=True)\n",
    "matrix_acc(training_pred_df.drop('truth', axis=1), training_pred_df['truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on the test set\n",
    "final_prediction = EL.predict(test_set.drop(dep_variable, axis = 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a063a9d6d4095dba70f7d4a438ef288e94ffec589b0525f5b20de998ec61033a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
